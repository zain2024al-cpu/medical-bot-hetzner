#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“„ PDF Generator with AI Insights
Ù…Ø­Ø±Ùƒ PDF Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Ø±Ø¤Ù‰ Ø°ÙƒÙŠØ© Ù…Ù† AI
"""

import os
import logging
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from jinja2 import Environment, FileSystemLoader
# import pdfkit  # Ù…Ø¹Ø·Ù„ - Ù†Ø³ØªØ®Ø¯Ù… WeasyPrint

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
load_dotenv(".env")
load_dotenv("config.env")

logger = logging.getLogger(__name__)

# Paths (absolute)
BASE_DIR = Path(__file__).resolve().parent.parent
TEMPLATE_DIR = str(BASE_DIR / "templates")
OUTPUT_DIR = str(BASE_DIR / "exports")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# OpenAI
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")

# PDF Options
DEFAULT_PDF_OPTIONS = {
    'enable-local-file-access': None,
    'print-media-type': None,
    'encoding': 'UTF-8',
    'page-size': 'A4',
    'margin-top': '20mm',
    'margin-right': '20mm',
    'margin-bottom': '20mm',
    'margin-left': '20mm',
    'dpi': 300,
}

# ====================================================
# ğŸ¤– PDF Ù…Ø¹ Ø±Ø¤Ù‰ AI
# ====================================================

async def generate_ai_enhanced_report(patient_data: Dict, reports: List[Dict]) -> str:
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± PDF Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Ø±Ø¤Ù‰ AI
    
    Args:
        patient_data: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙŠØ¶
        reports: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
    
    Returns:
        str: Ù…Ø³Ø§Ø± Ù…Ù„Ù PDF
    """
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ù€ AI
        ai_insights = None
        if OPENAI_API_KEY:
            logger.info("ğŸ¤– Generating AI insights for PDF...")
            ai_insights = await generate_patient_insights(patient_data, reports)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù„Ø¨
        env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))
        template = env.get_template('patient_history_ai.html')
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        context = {
            'patient': patient_data,
            'reports': reports,
            'ai_insights': ai_insights,
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'has_ai': ai_insights is not None
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ HTML
        html_content = template.render(**context)
        
        # Ø¥Ù†Ø´Ø§Ø¡ PDF
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = os.path.join(OUTPUT_DIR, f"patient_ai_{patient_data.get('id', 'x')}_{timestamp}.pdf")
        
        pdfkit.from_string(html_content, output_path, options=DEFAULT_PDF_OPTIONS)
        
        logger.info(f"âœ… AI-enhanced PDF created: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"âŒ PDF creation error: {e}")
        raise


async def generate_patient_insights(patient_data: Dict, reports: List[Dict]) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø¤Ù‰ Ø°ÙƒÙŠØ© Ù„Ù„Ù…Ø±ÙŠØ¶"""
    if not OPENAI_API_KEY:
        return None
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø·Ø¨ÙŠ
        medical_history = "\n".join([
            f"- {r.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {r.get('complaint', '')} â†’ {r.get('decision', '')}"
            for r in reports[-15:]  # Ø¢Ø®Ø± 15 ØªÙ‚Ø±ÙŠØ±
        ])
        
        patient_summary = f"""
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±ÙŠØ¶:
- Ø§Ù„Ø§Ø³Ù…: {patient_data.get('full_name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø§Ù„Ø¹Ù…Ø±: {patient_data.get('age', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø¹Ø¯Ø¯ Ø§Ù„Ø²ÙŠØ§Ø±Ø§Øª: {len(reports)}

Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø·Ø¨ÙŠ (Ø¢Ø®Ø± 15 Ø²ÙŠØ§Ø±Ø©):
{medical_history}
"""
        
        def call_openai():
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "Ø£Ù†Øª Ø·Ø¨ÙŠØ¨ Ø§Ø³ØªØ´Ø§Ø±ÙŠ Ù…ØªØ®ØµØµ. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø·Ø¨ÙŠ Ù„Ù„Ù…Ø±ÙŠØ¶ ÙˆÙ‚Ø¯Ù…:\n"
                                 "1. **Ù…Ù„Ø®Øµ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­ÙŠØ©**\n"
                                 "2. **Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸** (ØªØ­Ø³Ù†/ØªØ¯Ù‡ÙˆØ±/Ù…Ø³ØªÙ‚Ø±)\n"
                                 "3. **Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©**\n"
                                 "4. **ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©**\n\n"
                                 "Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ù…Ù†Ø¸Ù…Ø§Ù‹ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
                    },
                    {
                        "role": "user",
                        "content": f"Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø·Ø¨ÙŠ ÙˆÙ‚Ø¯Ù… ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹:\n\n{patient_summary}"
                    }
                ],
                temperature=0.4,
                max_tokens=600
            )
            return response.choices[0].message.content.strip()
        
        insights = await asyncio.to_thread(call_openai)
        return insights
        
    except Exception as e:
        logger.error(f"Insights generation error: {e}")
        return None


async def generate_analysis_summary_pdf(analysis_data: Dict) -> str:
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Ø±Ø¤Ù‰ AI
    """
    try:
        # Ø±Ø¤Ù‰ AI Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        ai_summary = None
        if OPENAI_API_KEY:
            ai_summary = await generate_analysis_insights(analysis_data)
        
        # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))
        template = env.get_template('analytics_report_ai.html')
        
        context = {
            **analysis_data,
            'ai_summary': ai_summary,
            'has_ai': ai_summary is not None,
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        html_content = template.render(**context)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = os.path.join(OUTPUT_DIR, f"analysis_ai_{timestamp}.pdf")
        
        pdfkit.from_string(html_content, output_path, options=DEFAULT_PDF_OPTIONS)
        
        logger.info(f"âœ… Analysis PDF with AI created: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"Analysis PDF error: {e}")
        raise


async def generate_analysis_insights(data: Dict) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø¤Ù‰ Ø°ÙƒÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„"""
    if not OPENAI_API_KEY:
        return None
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        data_summary = f"""
ğŸ“Š **Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©:**
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±: {data.get('total_reports', 0)}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø±Ø¶Ù‰: {data.get('total_patients', 0)}
- Ø§Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª: {data.get('hospitals_count', 0)}
- Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡: {data.get('doctors_count', 0)}

ğŸ“ˆ **Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹:**
- Ø£ÙƒØ«Ø± Ù…Ø³ØªØ´ÙÙ‰: {data.get('top_hospital', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø£ÙƒØ«Ø± Ù‚Ø³Ù…: {data.get('top_department', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø£ÙƒØ«Ø± Ø¥Ø¬Ø±Ø§Ø¡: {data.get('top_action', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
"""
        
        def call_openai():
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø·Ø¨ÙŠØ© Ø®Ø¨ÙŠØ±. Ø­Ù„Ù„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆÙ‚Ø¯Ù…:\n"
                                 "1. **Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©** (Ø£Ù‡Ù… 3 Ù…Ù„Ø§Ø­Ø¸Ø§Øª)\n"
                                 "2. **Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª** (Ù…Ø§ ÙŠØ­Ø¯Ø«)\n"
                                 "3. **Ø§Ù„ØªÙˆØµÙŠØ§Øª** (Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ©)\n"
                                 "4. **Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª** (Ù…Ø§ Ù‡Ùˆ Ù…ØªÙˆÙ‚Ø¹)"
                    },
                    {
                        "role": "user",
                        "content": f"Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© ÙˆÙ‚Ø¯Ù… Ø±Ø¤Ù‰ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:\n\n{data_summary}"
                    }
                ],
                temperature=0.5,
                max_tokens=700
            )
            return response.choices[0].message.content.strip()
        
        insights = await asyncio.to_thread(call_openai)
        return insights
        
    except Exception as e:
        logger.error(f"Analysis insights error: {e}")
        return None


# ====================================================
# ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø±
# ====================================================

if __name__ == "__main__":
    async def test():
        print("="*60)
        print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± PDF AI Enhanced")
        print("="*60)
        
        test_data = {
            'total_reports': 150,
            'total_patients': 45,
            'hospitals_count': 5,
            'doctors_count': 12,
            'top_hospital': 'Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù„Ùƒ ÙÙŠØµÙ„',
            'top_department': 'Ø§Ù„Ø·ÙˆØ§Ø±Ø¦',
            'top_action': 'ÙØ­Øµ Ø³Ø±ÙŠØ±ÙŠ'
        }
        
        insights = await generate_analysis_insights(test_data)
        if insights:
            print("\nğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø°ÙƒÙŠØ©:")
            print(insights)
        else:
            print("\nâš ï¸ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ±")
        
        print("\n" + "="*60)
    
    asyncio.run(test())

