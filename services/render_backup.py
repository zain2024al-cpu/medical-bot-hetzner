# ================================================
# services/render_backup.py
# ðŸ”¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù€ Render
# ================================================

import os
import shutil
import logging
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

# ================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
# ================================================

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ø§Ù„Ù…Ø³Ø§Ø± Ù…Ù† db/session.py Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù€ Render
try:
    from db.session import DATABASE_PATH as DB_PATH
    # ÙÙŠ RenderØŒ Ø§Ø³ØªØ®Ø¯Ù… /app/db/medical_reports.dbØŒ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø§Ø³ØªØ®Ø¯Ù… db/medical_reports.db
    if os.path.exists("/app/db/medical_reports.db"):
        DATABASE_PATH = "/app/db/medical_reports.db"
        BACKUP_DIR = "/app/db/backups"
    else:
        DATABASE_PATH = DB_PATH
        BACKUP_DIR = os.path.join(os.path.dirname(DATABASE_PATH), "backups")
except:
    # Fallback
    DATABASE_PATH = os.getenv("DATABASE_PATH", "/app/db/medical_reports.db")
    BACKUP_DIR = os.getenv("BACKUP_DIR", "/app/db/backups")

MAX_LOCAL_BACKUPS = int(os.getenv("MAX_LOCAL_BACKUPS", "10"))  # Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…Ø­Ù„ÙŠØ©


# ================================================
# Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ
# ================================================

def _run_integrity_check(db_file: str) -> bool:
    """ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© backup ÙˆÙ„ÙŠØ³ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø­ÙŠ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†)."""
    try:
        conn = sqlite3.connect(db_file, timeout=30)
        cur = conn.cursor()
        cur.execute("PRAGMA integrity_check")
        row = cur.fetchone()
        conn.close()
        return bool(row and str(row[0]).strip().lower() == "ok")
    except Exception as e:
        logger.error(f"âŒ integrity_check failed for {db_file}: {e}")
        return False


def _checkpoint_wal(db_file: str):
    """ØªÙ‚Ù„ÙŠÙ„ Ù…Ø®Ø§Ø·Ø± ØªÙ„Ù Ø§Ù„Ù†Ø³Ø® Ø¹Ø¨Ø± checkpoint Ù„Ù…Ù„ÙØ§Øª WAL Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø³Ø®."""
    try:
        conn = sqlite3.connect(db_file, timeout=30)
        cur = conn.cursor()
        # PASSIVE avoids forcing a heavy lock during active bot traffic.
        cur.execute("PRAGMA wal_checkpoint(PASSIVE)")
        conn.commit()
        conn.close()
    except Exception as e:
        logger.warning(f"âš ï¸ WAL checkpoint skipped: {e}")


def _sqlite_backup_copy(src_db: str, dst_db: str):
    """Ù†Ø³Ø® Ø¢Ù…Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SQLite backup API Ø¨Ø¯Ù„ copy2 Ø§Ù„Ù…Ø¨Ø§Ø´Ø±."""
    src_conn = sqlite3.connect(f"file:{src_db}?mode=ro", uri=True, timeout=60)
    try:
        dst_conn = sqlite3.connect(dst_db, timeout=60)
        try:
            src_conn.backup(dst_conn, pages=1000, sleep=0.01)
            dst_conn.commit()
        finally:
            dst_conn.close()
    finally:
        src_conn.close()


def create_local_backup(prefix: str = "backup") -> Optional[str]:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø­Ù„ÙŠØ© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    
    Returns:
        Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø£Ùˆ None Ø¥Ø°Ø§ ÙØ´Ù„
    """
    try:
        if not os.path.exists(DATABASE_PATH):
            logger.warning(f"âš ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {DATABASE_PATH}")
            return None
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        os.makedirs(BACKUP_DIR, exist_ok=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"{prefix}_{timestamp}.db"
        backup_path = os.path.join(BACKUP_DIR, backup_filename)

        # WAL checkpoint + SQLite backup API = Ù†Ø³Ø®Ø© Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§Ù‹ Ù…Ù† copy2
        _checkpoint_wal(DATABASE_PATH)
        _sqlite_backup_copy(DATABASE_PATH, backup_path)

        # ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙˆØ±Ø§Ù‹
        if not _run_integrity_check(backup_path):
            try:
                os.remove(backup_path)
            except Exception:
                pass
            logger.error("âŒ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙØ´Ù„Øª integrity_check ÙˆØªÙ… Ø­Ø°ÙÙ‡Ø§")
            return None
        
        db_size = os.path.getsize(DATABASE_PATH) / 1024
        backup_size = os.path.getsize(backup_path) / 1024
        
        logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø­Ù„ÙŠØ©")
        logger.info(f"   ðŸ“ Ø§Ù„Ù…Ø³Ø§Ø±: {backup_path}")
        logger.info(f"   ðŸ’¾ Ø§Ù„Ø­Ø¬Ù…: {backup_size:.2f} KB (Ø§Ù„Ø£ØµÙ„: {db_size:.2f} KB)")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        cleanup_old_backups()
        
        return backup_path
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
        import traceback
        traceback.print_exc()
        return None


def cleanup_old_backups():
    """Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± N Ù†Ø³Ø®Ø©)"""
    try:
        if not os.path.exists(BACKUP_DIR):
            return
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backups = []
        for file in os.listdir(BACKUP_DIR):
            if file.endswith(".db") and (
                file.startswith("backup_")
                or file.startswith("quick_")
                or file.startswith("daily_")
            ):
                file_path = os.path.join(BACKUP_DIR, file)
                mtime = os.path.getmtime(file_path)
                backups.append((mtime, file_path))
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        backups.sort(reverse=True)
        
        # Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        if len(backups) > MAX_LOCAL_BACKUPS:
            for mtime, file_path in backups[MAX_LOCAL_BACKUPS:]:
                try:
                    os.remove(file_path)
                    logger.info(f"ðŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù‚Ø¯ÙŠÙ…Ø©: {os.path.basename(file_path)}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ Ø­Ø°Ù Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")


def restore_from_local_backup(backup_filename: str) -> bool:
    """
    Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø­Ù„ÙŠØ©
    
    Args:
        backup_filename: Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    
    Returns:
        True Ø¥Ø°Ø§ Ù†Ø¬Ø­Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
    """
    try:
        backup_path = os.path.join(BACKUP_DIR, backup_filename)
        
        if not os.path.exists(backup_path):
            logger.error(f"âŒ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {backup_path}")
            return False
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        if os.path.exists(DATABASE_PATH):
            current_backup = f"{DATABASE_PATH}.before_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(DATABASE_PATH, current_backup)
            logger.info(f"ðŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {current_backup}")
        
        # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù† Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        shutil.copy2(backup_path, DATABASE_PATH)
        
        logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: {backup_filename}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return False


def list_local_backups() -> list:
    """
    Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
    
    Returns:
        Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    """
    backups = []
    
    try:
        if not os.path.exists(BACKUP_DIR):
            return backups
        
        for file in os.listdir(BACKUP_DIR):
            if file.startswith("backup_") and file.endswith(".db"):
                file_path = os.path.join(BACKUP_DIR, file)
                mtime = os.path.getmtime(file_path)
                size = os.path.getsize(file_path) / 1024
                
                backups.append({
                    "filename": file,
                    "path": file_path,
                    "size_kb": size,
                    "modified": datetime.fromtimestamp(mtime)
                })
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        backups.sort(key=lambda x: x["modified"], reverse=True)
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
    
    return backups


def get_latest_backup() -> Optional[str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    backups = list_local_backups()
    if backups:
        return backups[0]["path"]
    return None


# ================================================
# Ø¯Ø§Ù„Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
# ================================================

def auto_backup_job():
    """Ù…Ù‡Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (ØªÙØ³ØªØ¯Ø¹Ù‰ Ù…Ù† scheduler)"""
    try:
        backup_path = create_local_backup(prefix="quick")
        if backup_path:
            logger.info(f"âœ… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù†Ø¬Ø­: {backup_path}")
            return True
        else:
            logger.warning("âš ï¸ ÙØ´Ù„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
            return False
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}")
        return False


def create_monthly_archive(year: Optional[int] = None, month: Optional[int] = None) -> Optional[str]:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø±Ø´ÙŠÙ Ø´Ù‡Ø±ÙŠ (SQLite) Ù„Ù„ØªÙ‚Ø§Ø±ÙŠØ±:
    - Ù…Ù„Ù Ù…Ø³ØªÙ‚Ù„ Ù„ÙƒÙ„ Ø´Ù‡Ø±
    - ÙŠÙÙŠØ¯ ÙÙŠ Ø§Ù„Ø­ÙØ¸ Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø£Ø«Ø± Ø£ÙŠ ØªÙ„Ù Ù„Ø§Ø­Ù‚
    """
    try:
        now = datetime.utcnow()
        if year is None or month is None:
            # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹: Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
            if now.month == 1:
                year, month = now.year - 1, 12
            else:
                year, month = now.year, now.month - 1

        start = f"{year}-{month:02d}-01 00:00:00"
        if month == 12:
            end = f"{year + 1}-01-01 00:00:00"
        else:
            end = f"{year}-{month + 1:02d}-01 00:00:00"

        os.makedirs(BACKUP_DIR, exist_ok=True)
        archive_name = f"archive_{year}_{month:02d}.db"
        archive_path = os.path.join(BACKUP_DIR, archive_name)

        # Ù„Ø§ Ù†Ø¹ÙŠØ¯ Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙØ³ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙˆØ³Ù„ÙŠÙ…Ù‹Ø§
        if os.path.exists(archive_path) and _run_integrity_check(archive_path):
            logger.info(f"â„¹ï¸ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ø´Ù‡Ø±ÙŠ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹: {archive_name}")
            return archive_path

        if os.path.exists(archive_path):
            os.remove(archive_path)

        _checkpoint_wal(DATABASE_PATH)
        src_conn = sqlite3.connect(DATABASE_PATH, timeout=60)
        dst_conn = sqlite3.connect(archive_path, timeout=60)
        try:
            src_cur = src_conn.cursor()
            dst_cur = dst_conn.cursor()
            src_cur.execute(
                "SELECT sql FROM sqlite_master WHERE type='table' AND name='reports'"
            )
            create_sql_row = src_cur.fetchone()
            if not create_sql_row or not create_sql_row[0]:
                raise RuntimeError("reports table schema not found")

            dst_cur.execute(create_sql_row[0])
            dst_cur.execute(
                "INSERT INTO reports SELECT * FROM main.reports "
                "WHERE COALESCE(report_date, created_at) >= ? "
                "AND COALESCE(report_date, created_at) < ?",
                (start, end),
            )
            # ÙÙ‡Ø§Ø±Ø³ Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù„Ø§Ø­Ù‚Ø©
            dst_cur.execute("CREATE INDEX IF NOT EXISTS idx_reports_id ON reports(id)")
            dst_cur.execute("CREATE INDEX IF NOT EXISTS idx_reports_report_date ON reports(report_date)")
            dst_cur.execute("CREATE INDEX IF NOT EXISTS idx_reports_created_at ON reports(created_at)")
            dst_conn.commit()
        finally:
            dst_conn.close()
            src_conn.close()

        if not _run_integrity_check(archive_path):
            try:
                os.remove(archive_path)
            except Exception:
                pass
            logger.error(f"âŒ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ø´Ù‡Ø±ÙŠ ÙØ´Ù„ integrity_check: {archive_name}")
            return None

        logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ø´Ù‡Ø±ÙŠ: {archive_path}")
        return archive_path
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ø´Ù‡Ø±ÙŠ: {e}")
        return None


# ================================================
# ØªØµØ¯ÙŠØ±
# ================================================

__all__ = [
    'create_local_backup',
    'create_monthly_archive',
    'restore_from_local_backup',
    'list_local_backups',
    'get_latest_backup',
    'cleanup_old_backups',
    'auto_backup_job',
]

