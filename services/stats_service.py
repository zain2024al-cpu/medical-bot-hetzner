# ================================================
# services/stats_service.py
# Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯ ÙˆØ§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ†
# ================================================
#
# Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©: ÙƒÙ„ Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ­ØªØ§Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ØªØ±Ø¬Ù…ÙŠÙ†
# ÙŠØ³ØªØ¯Ø¹ÙŠ get_monthly_stats() Ø£Ùˆ get_translator_stats() Ù…Ù† Ù‡Ù†Ø§ ÙÙ‚Ø·.
# Ù„Ø§ ÙŠÙØ³Ù…Ø­ Ø¨Ø£ÙŠ Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙ‚Ù„ ÙÙŠ Ø£ÙŠ Ù…Ù„Ù Ø¢Ø®Ø±.
#
# Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø±Ø³Ù…ÙŠ:
#   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±: COUNT(*) WHERE status='active' AND translator_id IS NOT NULL
#   - Ø£ÙŠØ§Ù… Ø§Ù„Ø­Ø¶ÙˆØ± (attendance_days): COUNT(DISTINCT DATE(created_at)) - Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØªÙŠ Ø±ÙØ¹ ÙÙŠÙ‡Ø§ ØªÙ‚Ø§Ø±ÙŠØ±
#   - Ø£ÙŠØ§Ù… Ø§Ù„Ø¹Ù…Ù„ (work_days): Ù†ÙØ³ Ø£ÙŠØ§Ù… Ø§Ù„Ø­Ø¶ÙˆØ± (ÙƒÙ„ ÙŠÙˆÙ… Ù†ÙØ´Ø± ÙÙŠÙ‡ ØªÙ‚Ø±ÙŠØ± = ÙŠÙˆÙ… Ø¯ÙˆØ§Ù…)
#   - Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©: created_at hour >= 20
# ================================================

import logging
import sqlite3
from datetime import datetime, date, timedelta
from sqlalchemy import text
from db.session import DATABASE_PATH

logger = logging.getLogger(__name__)


def _parse_datetime(value):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†ØµÙŠ/Ø§Ù„ÙƒØ§Ø¦Ù†ÙŠ Ø¥Ù„Ù‰ datetime Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†."""
    if value is None:
        return None
    if isinstance(value, datetime):
        return value
    if isinstance(value, date):
        return datetime.combine(value, datetime.min.time())

    s = str(value).strip()
    if not s:
        return None

    for fmt in (
        "%Y-%m-%d %H:%M:%S.%f",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d",
    ):
        try:
            return datetime.strptime(s, fmt)
        except Exception:
            continue
    return None

# Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø±Ø³Ù…ÙŠØ© (13 Ù†ÙˆØ¹)
ALL_ACTION_TYPES = [
    "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø©", "Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…Ø¹ Ù‚Ø±Ø§Ø± Ø¹Ù…Ù„ÙŠØ©", "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø£Ø®ÙŠØ±Ø©",
    "Ø·ÙˆØ§Ø±Ø¦", "Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Ø§Ù„Ø±Ù‚ÙˆØ¯", "Ù…Ø±Ø§Ø¬Ø¹Ø© / Ø¹ÙˆØ¯Ø© Ø¯ÙˆØ±ÙŠØ©",
    "Ø¹Ù…Ù„ÙŠØ©", "Ø¹Ù„Ø§Ø¬ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ£Ù‡ÙŠÙ„", "ØªØ±Ù‚ÙŠØ¯",
    "Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰", "Ø£Ø´Ø¹Ø© ÙˆÙØ­ÙˆØµØ§Øª", "ØªØ£Ø¬ÙŠÙ„ Ù…ÙˆØ¹Ø¯", "Ø¬Ù„Ø³Ø© Ø¥Ø´Ø¹Ø§Ø¹ÙŠ"
]


def _run_translator_query(session, start_date_str: str, end_date_str: str):
    """
    Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ø§Ù„ÙˆØ­ÙŠØ¯ - ÙŠÙØ³ØªØ¯Ø¹Ù‰ Ø¯Ø§Ø®Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.
    Ù„Ø§ ÙŠØ¬Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù.

    Returns:
        list[dict] - Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ù…ØªØ±Ø¬Ù…
    """
    try:
        # â•â•â• Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø±Ø³Ù…ÙŠ Ø§Ù„ÙˆØ­ÙŠØ¯ â•â•â•
        # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… TranslatorDirectory ÙƒÙ…Ø±Ø¬Ø¹ Ø£Ø³Ø§Ø³ÙŠ Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
        # âœ… ØªØ­ÙˆÙŠÙ„ created_at Ù…Ù† UTC Ø¥Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…Ø­Ù„ÙŠ (UTC+5:30) Ù‚Ø¨Ù„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø³Ø§Ø¹Ø©
        # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… COALESCE(report_date, created_at) Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙÙ‚Ø¯Ø§Ù† ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø¯ÙˆÙ† report_date
        # âœ… Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ø§Ù„Ø§Ø³Ù… (Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† Ù„Ù‡Ù… Ø£ÙƒØ«Ø± Ù…Ù† translator_id)
        sql = text("""
            SELECT
                MIN(r.translator_id) as translator_id,
                COALESCE(td.name, r.translator_name, 'Ù…ØªØ±Ø¬Ù… #' || r.translator_id) as translator_name,
                COUNT(*) as total_reports,
                COUNT(DISTINCT DATE(COALESCE(r.report_date, r.created_at))) as attendance_days,
                SUM(
                    CASE WHEN CAST(strftime('%H', datetime(r.created_at, '+5 hours', '+30 minutes')) AS INTEGER) >= 20
                    THEN 1 ELSE 0 END
                ) as late_reports
            FROM reports r
            LEFT JOIN translators td ON r.translator_id = td.translator_id
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NOT NULL
            GROUP BY COALESCE(td.name, r.translator_name)
            ORDER BY total_reports DESC
        """)

        rows = session.execute(sql, {"start": start_date_str, "end": end_date_str}).fetchall()

        # â•â•â• LOG: Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ† ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ± â•â•â•
        logger.info(f"ğŸ“Š stats_service: range=[{start_date_str} â†’ {end_date_str}], translators={len(rows)}")
        for row in rows:
            logger.info(f"   â”œ tid={row[0]}, name={row[1]}, reports={row[2]}, days={row[3]}, late={row[4]}")

        # â•â•â• LOG: Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø¯ÙˆÙ† ØªØ¬Ù…ÙŠØ¹ â•â•â•
        count_sql = text("""
            SELECT COUNT(*) FROM reports r
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
        """)
        total_all = session.execute(count_sql, {"start": start_date_str, "end": end_date_str}).scalar()

        count_with_tid = text("""
            SELECT COUNT(*) FROM reports r
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NOT NULL
        """)
        total_with_tid = session.execute(count_with_tid, {"start": start_date_str, "end": end_date_str}).scalar()

        count_no_tid = text("""
            SELECT COUNT(*) FROM reports r
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NULL
        """)
        total_no_tid = session.execute(count_no_tid, {"start": start_date_str, "end": end_date_str}).scalar()

        logger.info(f"ğŸ“Š stats_service: total_all={total_all}, with_tid={total_with_tid}, without_tid={total_no_tid}")

        # â•â•â• Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªÙØµÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª (Ù…Ø¬Ù…Ù‘Ø¹ Ø¨Ø§Ù„Ø§Ø³Ù…) â•â•â•
        action_sql = text("""
            SELECT
                COALESCE(td.name, r.translator_name) as tname,
                COALESCE(r.medical_action, 'Ø£Ø®Ø±Ù‰') as action_type,
                COUNT(*) as action_count
            FROM reports r
            LEFT JOIN translators td ON r.translator_id = td.translator_id
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NOT NULL
            GROUP BY tname, action_type
        """)

        action_rows = session.execute(action_sql, {"start": start_date_str, "end": end_date_str}).fetchall()

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³Ù…
        action_map = {}
        for row in action_rows:
            tname = row[0]
            action_type = row[1] or "Ø£Ø®Ø±Ù‰"
            count = row[2]
            if tname not in action_map:
                action_map[tname] = {}
            action_map[tname][action_type] = count

        # â•â•â• Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ÙƒØ±Ø±Ø© (Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… + Ù†ÙØ³ Ø§Ù„Ù…Ø±ÙŠØ¶ + Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ…) â•â•â•
        dup_sql = text("""
            SELECT COALESCE(td.name, r.translator_name) as tname,
                   COUNT(*) - COUNT(DISTINCT r.patient_name || '|' || DATE(COALESCE(r.report_date, r.created_at))) as duplicates
            FROM reports r
            LEFT JOIN translators td ON r.translator_id = td.translator_id
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NOT NULL
            GROUP BY tname
        """)
        dup_rows = session.execute(dup_sql, {"start": start_date_str, "end": end_date_str}).fetchall()
        dup_map = {row[0]: max(row[1], 0) for row in dup_rows}

        # â•â•â• Ù…ØªÙˆØ³Ø· Ø³Ø§Ø¹Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„ÙƒÙ„ Ù…ØªØ±Ø¬Ù… Ø¨Ø§Ù„Ø§Ø³Ù… (Ø¨ØªÙˆÙ‚ÙŠØª IST) â•â•â•
        avg_hour_sql = text("""
            SELECT COALESCE(td.name, r.translator_name) as tname,
                   AVG(CAST(strftime('%H', datetime(r.created_at, '+5 hours', '+30 minutes')) AS REAL)
                       + CAST(strftime('%M', datetime(r.created_at, '+5 hours', '+30 minutes')) AS REAL) / 60.0
                   ) as avg_hour
            FROM reports r
            LEFT JOIN translators td ON r.translator_id = td.translator_id
            WHERE COALESCE(r.report_date, r.created_at) >= :start
            AND COALESCE(r.report_date, r.created_at) < :end
            AND r.status = 'active'
            AND r.translator_id IS NOT NULL
            GROUP BY tname
        """)
        avg_hour_rows = session.execute(avg_hour_sql, {"start": start_date_str, "end": end_date_str}).fetchall()
        avg_hour_map = {row[0]: round(row[1], 1) if row[1] is not None else None for row in avg_hour_rows}

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        results = []
        for row in rows:
            tid = row[0]
            name = row[1]
            total = row[2]
            attendance_days = row[3]  # Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØªÙŠ Ø±ÙØ¹ ÙÙŠÙ‡Ø§ ØªÙ‚Ø§Ø±ÙŠØ± ÙØ¹Ù„Ø§Ù‹
            late = row[4] or 0
            work_days = attendance_days

            # Ø¨Ù†Ø§Ø¡ action_breakdown Ù…Ø¹ Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙ„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù€ 13
            # âœ… Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù… (Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ† Ø°ÙˆÙŠ Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ù† ID)
            raw_actions = action_map.get(name, {})
            action_breakdown = {a: 0 for a in ALL_ACTION_TYPES}
            for action_name, count in raw_actions.items():
                action_name_clean = (action_name or "").strip()
                if action_name_clean in action_breakdown:
                    action_breakdown[action_name_clean] = count
                elif action_name_clean:
                    action_breakdown[action_name_clean] = count

            results.append({
                "translator_id": tid,
                "translator_name": name,
                "total_reports": total,
                "work_days": work_days,
                "attendance_days": attendance_days,
                "late_reports": late,
                "duplicate_reports": dup_map.get(name, 0),
                "avg_hour": avg_hour_map.get(name),
                "action_breakdown": action_breakdown,
                "start_date": start_date_str,
                "end_date": end_date_str,
            })

        return results

    except Exception as e:
        error_text = str(e).lower()
        if "malformed" not in error_text and "disk image" not in error_text:
            raise

        logger.warning("âš ï¸ stats_service: DB appears malformed, using resilient fallback aggregation.")
        logger.warning(f"âš ï¸ stats_service fallback reason: {e}")
        return _run_translator_query_resilient(start_date_str, end_date_str)


def _run_translator_query_resilient(start_date_str: str, end_date_str: str):
    """
    Fallback resilient aggregation for partially corrupted SQLite DB.
    Reads reports row-by-row using id to skip unreadable rows.
    """
    start_dt = _parse_datetime(start_date_str)
    end_dt = _parse_datetime(end_date_str)
    if not start_dt or not end_dt:
        return []

    results_map = {}
    unreadable_rows = 0
    users_name_cache = {}

    con = sqlite3.connect(DATABASE_PATH)
    cur = con.cursor()

    # max id may still be readable even with partial corruption
    try:
        cur.execute("SELECT COALESCE(MAX(id), 0) FROM reports")
        max_id = int(cur.fetchone()[0] or 0)
    except Exception:
        con.close()
        return []

    for report_id in range(1, max_id + 1):
        try:
            cur.execute(
                "SELECT translator_id, translator_name, medical_action, report_date, created_at, status "
                "FROM reports WHERE id = ?",
                (report_id,),
            )
            row = cur.fetchone()
        except Exception:
            unreadable_rows += 1
            continue

        if not row:
            continue

        translator_id, translator_name, medical_action, report_date, created_at, status = row
        if translator_id is None:
            continue
        if status and str(status).strip().lower() != "active":
            continue

        report_dt = _parse_datetime(report_date)
        created_dt = _parse_datetime(created_at)

        # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… COALESCE: report_date Ø£ÙˆÙ„Ø§Ù‹ØŒ ÙˆØ¥Ø°Ø§ ØºØ§Ø¨ Ù†Ø³ØªØ®Ø¯Ù… created_at
        if not report_dt:
            report_dt = created_dt
        if not report_dt:
            continue

        if not (start_dt <= report_dt < end_dt):
            continue

        tid = int(translator_id)
        if tid not in users_name_cache:
            try:
                # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… TranslatorDirectory Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† users
                cur.execute("SELECT name FROM translators WHERE translator_id = ?", (tid,))
                urow = cur.fetchone()
                users_name_cache[tid] = (urow[0] if urow and urow[0] else None)
            except Exception:
                users_name_cache[tid] = None

        display_name = users_name_cache.get(tid) or translator_name or f"Ù…ØªØ±Ø¬Ù… #{tid}"
        if tid not in results_map:
            results_map[tid] = {
                "translator_id": tid,
                "translator_name": str(display_name),
                "total_reports": 0,
                "attendance_dates": set(),
                "late_reports": 0,
                "action_breakdown": {a: 0 for a in ALL_ACTION_TYPES},
            }

        item = results_map[tid]
        item["total_reports"] += 1
        item["attendance_dates"].add(report_dt.date())
        # âœ… ØªØ­ÙˆÙŠÙ„ created_at Ù…Ù† UTC Ø¥Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…Ø­Ù„ÙŠ (UTC+5:30) Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        if created_dt:
            local_hour = created_dt.hour + 5 + (1 if created_dt.minute >= 30 else 0)
            if local_hour >= 24:
                local_hour -= 24
            if local_hour >= 20:
                item["late_reports"] += 1

        action_name = (medical_action or "Ø£Ø®Ø±Ù‰").strip() if medical_action else "Ø£Ø®Ø±Ù‰"
        if action_name in item["action_breakdown"]:
            item["action_breakdown"][action_name] += 1
        else:
            item["action_breakdown"][action_name] = item["action_breakdown"].get(action_name, 0) + 1

    con.close()

    if unreadable_rows > 0:
        logger.warning(f"âš ï¸ stats_service fallback skipped unreadable rows: {unreadable_rows}")

    results = []
    for _, item in sorted(results_map.items(), key=lambda kv: kv[1]["total_reports"], reverse=True):
        attendance_days = len(item["attendance_dates"])
        results.append({
            "translator_id": item["translator_id"],
            "translator_name": item["translator_name"],
            "total_reports": item["total_reports"],
            "work_days": attendance_days,
            "attendance_days": attendance_days,
            "late_reports": item["late_reports"],
            "action_breakdown": item["action_breakdown"],
            "start_date": start_date_str,
            "end_date": end_date_str,
        })

    return results


def get_monthly_stats(session, year: int, month):
    """
    Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ† Ù„Ø´Ù‡Ø± Ù…Ø­Ø¯Ø¯ Ø£Ùˆ Ø³Ù†Ø© ÙƒØ§Ù…Ù„Ø©.

    Parameters:
        session: SQLAlchemy session (must be open)
        year: int - Ø§Ù„Ø³Ù†Ø©
        month: int or "all" - Ø§Ù„Ø´Ù‡Ø± (1-12) Ø£Ùˆ "all" Ù„ÙƒÙ„ Ø§Ù„Ø³Ù†Ø©

    Returns:
        list[dict] - Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ ÙÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
    """
    if month == "all" or month == 0:
        start_date = f"{year}-01-01"
        end_date = f"{year + 1}-01-01"
    else:
        m = int(month)
        start_date = f"{year}-{m:02d}-01"
        if m == 12:
            end_date = f"{year + 1}-01-01"
        else:
            end_date = f"{year}-{m + 1:02d}-01"

    return _run_translator_query(session, start_date, end_date)


def get_translator_stats(session, start_date, end_date):
    """
    Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ±Ø¬Ù…ÙŠÙ† Ù„ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©.

    Parameters:
        session: SQLAlchemy session (must be open)
        start_date: date or str - Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙØªØ±Ø©
        end_date: date or str - Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙØªØ±Ø© (exclusive)

    Returns:
        list[dict] - Ù†ÙØ³ Ø§Ù„ØµÙŠØºØ© ÙƒÙ€ get_monthly_stats
    """
    if isinstance(start_date, (date, datetime)):
        start_str = start_date.strftime("%Y-%m-%d")
    else:
        start_str = str(start_date)

    if isinstance(end_date, (date, datetime)):
        # Ù†Ø¶ÙŠÙ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ Ù„Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© exclusive
        if isinstance(end_date, date) and not isinstance(end_date, datetime):
            end_dt = end_date + timedelta(days=1)
        else:
            end_dt = end_date + timedelta(days=1)
        end_str = end_dt.strftime("%Y-%m-%d")
    else:
        end_str = str(end_date)

    return _run_translator_query(session, start_str, end_str)
